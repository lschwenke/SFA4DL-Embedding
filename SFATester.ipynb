{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eed0822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "from modules import helper\n",
    "from modules import dataset_selecter as ds\n",
    "from modules import modelCreator\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.eager import context\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da6270",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrFolds= 5\n",
    "patience= 70\n",
    "seed_value= 56\n",
    "batchSize= 50\n",
    "useEmbed= False # for now removed\n",
    "calcOri= True # calc the original model\n",
    "calcSFA= True # calc the original model\n",
    "doSymbolify= True # symbolify the data (if the data is maybe already symbolified)\n",
    "useSaves= False # dont calculate already calcluated model runs\n",
    "useShapeSaves= False\n",
    "multiVariant= False # not working right now\n",
    "skipDebugSaves= False # reduces the saved amount of data\n",
    "dropeOutRate= 0.3\n",
    "takeAvg= True # False if one specific Transformer layer should be used\n",
    "heatLayer= -1 # The Layer which should be used if takeAvg is False\n",
    "\n",
    "dataset= 'ucr' #\n",
    "takename= True #If True, take UTC names rather than numbers\n",
    "limit= 500 # max sequence size for a dataset\n",
    "numEpochs= 500\n",
    "\n",
    "\n",
    "#number of symbols\n",
    "symbolCount= 6\n",
    "\n",
    "numOfAttentionLayers=2\n",
    "\n",
    "# dataset to use from UCR\n",
    "number=\"Meat\"\n",
    "strategy='uniform'\n",
    "\n",
    "header= 8\n",
    "# number of coefs. [0] is the minimal coef size, weile [1] is a factor on how to handle sequences < [0]. [0,0] means SAX is getting used.\n",
    "ncoef= [0, 0] #[256, 1]  [128, 2], [64, 4], [0,0]\n",
    "\n",
    "dmodel=16\n",
    "dff= 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777262d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED']=str(seed_value)# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "random.seed(seed_value)# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "tf.random.set_seed(seed_value)\n",
    "np.random.RandomState(seed_value)\n",
    "\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "context.set_global_seed(seed_value)\n",
    "ops.get_default_graph().seed = seed_value\n",
    "\n",
    "#pip install tensorflow-determinism needed\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "#save some variables for later\n",
    "valuesA = helper.getMapValues(symbolCount)\n",
    "kf = StratifiedKFold(nrFolds, shuffle=True, random_state=seed_value)\n",
    "earlystop = EarlyStopping(monitor= 'val_loss', min_delta=0 , patience=patience, verbose=0, mode='auto',restore_best_weights=True)\n",
    "fold = 0\n",
    "\n",
    "#init gpu\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for gpu_instance in physical_devices: \n",
    "    tf.config.experimental.set_memory_growth(gpu_instance, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a304a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, y_trainy, y_testy, seqSize, dataName, num_of_classes, number = ds.datasetSelector(dataset, seed_value, number, takeName=takename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17a6921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillOutDicWithNNOutFull(abstractionString, configString, fullResults, inputDict):\n",
    "    if abstractionString not in fullResults.keys():\n",
    "        fullResults[abstractionString] = dict()\n",
    "    if configString not in fullResults[abstractionString].keys():\n",
    "        fullResults[abstractionString][configString] = []\n",
    "    fullResults[abstractionString][configString].append(inputDict)\n",
    "\n",
    "\n",
    "\n",
    "def fillOutDicWithNNOut(abstractionString, configString, fullResults, outData):\n",
    "    inputDict = helper.fillOutDicWithNNOutSmall(outData)\n",
    "    fillOutDicWithNNOutFull(abstractionString, configString, fullResults, inputDict)\n",
    "\n",
    "def printTime():\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ff41ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")\n",
    "print('Dataname:')\n",
    "print(dataName)\n",
    "printTime()\n",
    "warnings.filterwarnings('ignore')   \n",
    "\n",
    "fullResults = dict()\n",
    "\n",
    "#limit the lenght of the data\n",
    "toLong = False\n",
    "dontRun = False\n",
    "if seqSize > limit:\n",
    "    if calcSFA and ncoef[0] != 0:\n",
    "        toLong = True\n",
    "        print('TO LONGE ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "        print('Only calculating SFA!')\n",
    "    else:\n",
    "        fullResults[\"Error\"] = \"dataset \" + dataName + \" to big: \" + str(seqSize)\n",
    "        print('TO LONGE ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "        print(\"dataset \" + dataName + \" to big: \" + str(seqSize))\n",
    "        dontRun = True\n",
    "\n",
    "if not dontRun:\n",
    "    # k fold train loop\n",
    "    for train, test in kf.split(X_train, y_trainy):\n",
    "        fold+=1    \n",
    "\n",
    "        #preprocess data\n",
    "        x_train1 = X_train[train]\n",
    "        x_val = X_train[test]\n",
    "        y_train1 = y_train[train]\n",
    "        y_trainy1 = y_trainy[train]\n",
    "        y_val = y_train[test]\n",
    "        \n",
    "        x_train1, x_val, x_test, y_train1, y_val, y_test, X_train_ori, X_val_ori, X_test_ori, y_trainy1, y_testy = modelCreator.preprocessData(x_train1, x_val, X_test, y_train1, y_val, y_test, y_trainy1, y_testy, fold, symbolCount, dataName, useEmbed = useEmbed, useSaves = useShapeSaves, doSymbolify = doSymbolify, multiVariant=multiVariant, strategy=strategy)\n",
    "\n",
    "        # calc original model\n",
    "        abstractionString = \"Original\"\n",
    "        if(calcOri and not toLong):\n",
    "            print('############################### calc ori')\n",
    "            outOri = modelCreator.doAbstractedTraining(X_train_ori, X_val_ori, X_test_ori, y_train1, y_val, y_testy, batchSize, seed_value, num_of_classes, dataName, fold, symbolCount, numEpochs, numOfAttentionLayers, dmodel, header, dff, skipDebugSaves=skipDebugSaves, useEmbed = useEmbed, earlystop = earlystop, useSaves=useSaves, \n",
    "            abstractionType=abstractionString, rate=dropeOutRate)\n",
    "            fillOutDicWithNNOut(abstractionString, \"results\", fullResults, outOri)\n",
    "        printTime()\n",
    "\n",
    "        # calc SAX or SFA model\n",
    "        if (not calcSFA) or (ncoef[0] == 0):\n",
    "            abstractionString = \"SAX\"\n",
    "            outSax = modelCreator.doAbstractedTraining(x_train1, x_val, x_test, y_train1, y_val, y_testy, batchSize, seed_value, num_of_classes, dataName, fold, symbolCount, numEpochs, numOfAttentionLayers, dmodel, header, dff, skipDebugSaves=skipDebugSaves, useEmbed = useEmbed, earlystop = earlystop, useSaves=useSaves, \n",
    "                abstractionType=abstractionString, rate=dropeOutRate)\n",
    "            printTime()\n",
    "            fillOutDicWithNNOut(abstractionString, \"results\", fullResults, outSax)   \n",
    "        else:\n",
    "            limitS = seqSize/ncoef[1]\n",
    "            if ncoef[0] > limitS:\n",
    "                ncoefI = int(limitS)\n",
    "            else:\n",
    "                ncoefI = ncoef[0]\n",
    "\n",
    "\n",
    "            x_train1 = X_train[train]\n",
    "            x_val = X_train[test]\n",
    "            y_train1 = y_train[train]\n",
    "            y_trainy1 = y_trainy[train]\n",
    "            y_val = y_train[test]\n",
    "\n",
    "            x_train1, x_val, x_test, y_train1, y_val, y_test, X_train_ori, X_val_ori, X_test_ori, y_trainy1, y_testy = modelCreator.preprocessData(x_train1, x_val, X_test, y_train1, y_val, y_test, y_trainy1, y_testy, fold, symbolCount, dataName, useEmbed = useEmbed, useSaves = useShapeSaves, doSymbolify = doSymbolify, multiVariant=multiVariant, doSFA=True, ncoef=ncoefI, strategy=strategy)\n",
    "\n",
    "            abstractionString = \"SFA\" + str(ncoef[1])\n",
    "            outSax = modelCreator.doAbstractedTraining(x_train1, x_val, x_test, y_train1, y_val, y_testy, batchSize, seed_value, num_of_classes, dataName, fold, symbolCount, numEpochs, numOfAttentionLayers, dmodel, header, dff, skipDebugSaves=skipDebugSaves, useEmbed = useEmbed, earlystop = earlystop, useSaves=useSaves, \n",
    "                abstractionType=abstractionString, rate=dropeOutRate, ncoef=ncoef[0])\n",
    "            printTime()\n",
    "            fillOutDicWithNNOut(abstractionString, \"results\", fullResults, outSax)\n",
    "            fullResults['ncoef']= ncoef\n",
    "\n",
    "        predictions = np.argmax(y_train1,axis=1) +1\n",
    "\n",
    "        print(\"finished fold: \" + str(fold))\n",
    "        printTime()   \n",
    "        break\n",
    "             \n",
    "    print(\"Done done\")\n",
    "    saveName = modelCreator.getWeightName(dataName, number, symbolCount, numOfAttentionLayers, \"results\", header, dmodel=dmodel, dff=dff,doDetails=True, learning = False, results = True, posthoc= str(ncoef[0]) + \" -st\" + strategy[0:1])\n",
    "    print(saveName)\n",
    "    helper.save_obj(fullResults, str(saveName))\n",
    "\n",
    "\n",
    "    printTime()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7f0c66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "0192e97c49aa006567516aa20ae8b230a0b19ef6e30d643f5f1bdd687e01fd42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
